{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generative ResNet Training on Tiny-ImageNet\n",
        "\n",
        "This notebook trains a generative ResNet model on the Tiny-ImageNet dataset using Predictive Coding Networks (PCM).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure matplotlib for inline display\n",
        "%matplotlib inline\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jr\n",
        "import equinox as eqx\n",
        "import optax\n",
        "\n",
        "from pcm.network import ChainNetwork, Vertex, Edge\n",
        "from pcm.blocks import (\n",
        "    LinearBlock, ResidualBlock, ResidualUpBlock, \n",
        "    ConvBlock, ConvTransposeBlock\n",
        ")\n",
        "from pcm.datasets import get_tiny_imagenet_dataloaders\n",
        "\n",
        "print(\"JAX version:\", jax.__version__)\n",
        "print(\"Devices:\", jax.devices())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Components\n",
        "\n",
        "Define the building blocks for the generative ResNet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ReshapeBlock(eqx.Module):\n",
        "    linear: eqx.nn.Linear\n",
        "    out_channels: int\n",
        "    spatial_size: int\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features: int,\n",
        "        out_channels: int,\n",
        "        spatial_size: int,\n",
        "        key: jax.Array = None,\n",
        "    ):\n",
        "        if key is None:\n",
        "            key = jr.PRNGKey(0)\n",
        "        \n",
        "        self.out_channels = out_channels\n",
        "        self.spatial_size = spatial_size\n",
        "\n",
        "        out_features = out_channels * spatial_size * spatial_size\n",
        "        self.linear = eqx.nn.Linear(\n",
        "            in_features=in_features,\n",
        "            out_features=out_features,\n",
        "            use_bias=True,\n",
        "            key=key\n",
        "        )\n",
        "    \n",
        "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
        "        out = jax.vmap(self.linear)(x)\n",
        "        batch_size = out.shape[0]\n",
        "        out = out.reshape(batch_size, self.out_channels, self.spatial_size, self.spatial_size)\n",
        "        out = jax.nn.relu(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FinalConvBlock(eqx.Module):\n",
        "    conv: eqx.nn.Conv2d\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int = 3,\n",
        "        key: jax.Array = None,\n",
        "    ):\n",
        "        if key is None:\n",
        "            key = jr.PRNGKey(0)\n",
        "        \n",
        "        self.conv = eqx.nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=out_channels,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "            use_bias=True,\n",
        "            key=key,\n",
        "        )\n",
        "    \n",
        "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
        "        out = jax.vmap(self.conv)(x)\n",
        "        # Use sigmoid to ensure output is in [0, 1]\n",
        "        out = jax.nn.sigmoid(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Network Architecture\n",
        "\n",
        "Create the generative ResNet using ChainNetwork."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_generative_resnet(\n",
        "    key,\n",
        "    latent_dim=128,\n",
        "    initial_channels=512,\n",
        "    initial_size=4,\n",
        "    img_size=64,\n",
        "):\n",
        "    \"\"\"\n",
        "    Create a generative ResNet using ChainNetwork.\n",
        "    \n",
        "    Architecture:\n",
        "    - Input: (1,) fixed to 0\n",
        "    - Embedding: Linear to latent_dim\n",
        "    - Reshape: latent_dim -> (initial_channels, initial_size, initial_size)\n",
        "    - ResidualBlock at initial_size\n",
        "    - ResidualUpBlock: initial_size -> initial_size*2  (4->8)\n",
        "    - ResidualBlock at initial_size*2\n",
        "    - ResidualUpBlock: initial_size*2 -> initial_size*4  (8->16)\n",
        "    - ResidualBlock at initial_size*4\n",
        "    - ResidualUpBlock: initial_size*4 -> initial_size*8  (16->32)\n",
        "    - ResidualBlock at initial_size*8\n",
        "    - ResidualUpBlock: initial_size*8 -> img_size  (32->64)\n",
        "    - ResidualBlock at img_size\n",
        "    - FinalConv: -> (3, 64, 64)\n",
        "    \"\"\"\n",
        "    \n",
        "    num_upsamples = int(jnp.log2(img_size / initial_size))\n",
        "    keys = jr.split(key, 20)  # Enough keys for all layers\n",
        "    key_idx = 0\n",
        "    \n",
        "    vertices = []\n",
        "    edges = []\n",
        "    \n",
        "    vertices.append(Vertex(name=\"input\", shape=(1,), fixed=True))\n",
        "    vertices.append(Vertex(name=\"latent\", shape=(latent_dim,), fixed=False))\n",
        "    edges.append(Edge(\n",
        "        from_v=vertices[-2],\n",
        "        to_v=vertices[-1],\n",
        "        forward_fn=LinearBlock(in_features=1, out_features=latent_dim, key=keys[key_idx])\n",
        "    ))\n",
        "    key_idx += 1\n",
        "    \n",
        "    current_channels = initial_channels\n",
        "    current_size = initial_size\n",
        "    vertices.append(Vertex(\n",
        "        name=\"spatial_0\",\n",
        "        shape=(current_channels, current_size, current_size),\n",
        "        fixed=False\n",
        "    ))\n",
        "    edges.append(Edge(\n",
        "        from_v=vertices[-2],\n",
        "        to_v=vertices[-1],\n",
        "        forward_fn=ReshapeBlock(\n",
        "            in_features=latent_dim,\n",
        "            out_channels=current_channels,\n",
        "            spatial_size=current_size,\n",
        "            key=keys[key_idx]\n",
        "        )\n",
        "    ))\n",
        "    key_idx += 1\n",
        "    \n",
        "    for i in range(num_upsamples):\n",
        "        vertices.append(Vertex(\n",
        "            name=f\"res_block_{i}_a\",\n",
        "            shape=(current_channels, current_size, current_size),\n",
        "            fixed=False\n",
        "        ))\n",
        "        edges.append(Edge(\n",
        "            from_v=vertices[-2],\n",
        "            to_v=vertices[-1],\n",
        "            forward_fn=ResidualBlock(\n",
        "                in_channels=current_channels,\n",
        "                out_channels=current_channels,\n",
        "                stride=1,\n",
        "                key=keys[key_idx]\n",
        "            )\n",
        "        ))\n",
        "        key_idx += 1\n",
        "        \n",
        "        next_size = current_size * 2\n",
        "        next_channels = max(current_channels // 2, 64)  # Decrease channels as we upsample\n",
        "        \n",
        "        vertices.append(Vertex(\n",
        "            name=f\"upsample_{i}\",\n",
        "            shape=(next_channels, next_size, next_size),\n",
        "            fixed=False\n",
        "        ))\n",
        "        edges.append(Edge(\n",
        "            from_v=vertices[-2],\n",
        "            to_v=vertices[-1],\n",
        "            forward_fn=ResidualUpBlock(\n",
        "                in_channels=current_channels,\n",
        "                out_channels=next_channels,\n",
        "                key=keys[key_idx]\n",
        "            )\n",
        "        ))\n",
        "        key_idx += 1\n",
        "        \n",
        "        current_channels = next_channels\n",
        "        current_size = next_size\n",
        "    \n",
        "    # Final ResidualBlock\n",
        "    vertices.append(Vertex(\n",
        "        name=\"res_block_final\",\n",
        "        shape=(current_channels, current_size, current_size),\n",
        "        fixed=False\n",
        "    ))\n",
        "    edges.append(Edge(\n",
        "        from_v=vertices[-2],\n",
        "        to_v=vertices[-1],\n",
        "        forward_fn=ResidualBlock(\n",
        "            in_channels=current_channels,\n",
        "            out_channels=current_channels,\n",
        "            stride=1,\n",
        "            key=keys[key_idx]\n",
        "        )\n",
        "    ))\n",
        "    key_idx += 1\n",
        "    \n",
        "    # Output vertex (RGB image, fixed during training)\n",
        "    vertices.append(Vertex(\n",
        "        name=\"output\",\n",
        "        shape=(3, img_size, img_size),\n",
        "        fixed=True\n",
        "    ))\n",
        "    edges.append(Edge(\n",
        "        from_v=vertices[-2],\n",
        "        to_v=vertices[-1],\n",
        "        forward_fn=FinalConvBlock(\n",
        "            in_channels=current_channels,\n",
        "            out_channels=3,\n",
        "            key=keys[key_idx]\n",
        "        )\n",
        "    ))\n",
        "    \n",
        "    network = ChainNetwork(edges=edges)\n",
        "    return network\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_images_grid(images, rows=4, cols=4, title=\"Generated Images\", save_path=None):\n",
        "    \"\"\"Plot a grid of images.\"\"\"\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 2, rows * 2))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, ax in enumerate(axes):\n",
        "        if idx < len(images):\n",
        "            # images shape: (3, 64, 64), need to transpose to (64, 64, 3)\n",
        "            img = images[idx].transpose(1, 2, 0)\n",
        "            img = jnp.clip(img, 0, 1)\n",
        "            ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "    \n",
        "    plt.suptitle(title)\n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "        print(f\"Saved figure to {save_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_images(network, key, num_samples=16):\n",
        "    \"\"\"Generate images from the network.\"\"\"\n",
        "    batch_size = num_samples\n",
        "    \n",
        "    input_states = {\n",
        "        \"input\": jnp.zeros((batch_size, 1))\n",
        "    }\n",
        "    \n",
        "    # Forward pass with generative=True\n",
        "    result = network.forward(\n",
        "        input_states=input_states,\n",
        "        returned_vertices=[\"output\"],\n",
        "        generative=True,\n",
        "        key=key\n",
        "    )\n",
        "    \n",
        "    return result[\"output\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_generative_model(\n",
        "    network,\n",
        "    train_loader,\n",
        "    key,\n",
        "    epochs=10,\n",
        "    train_lr=1e-4,\n",
        "    inf_lr=0.05,\n",
        "    inf_epoch=50,\n",
        "    generate_every=50,\n",
        "    num_generate=16,\n",
        "    save_dir=None,\n",
        "):\n",
        "    \"\"\"Train the generative ResNet model.\"\"\"\n",
        "    \n",
        "    # Create save directory if specified\n",
        "    if save_dir:\n",
        "        save_dir = Path(save_dir)\n",
        "        save_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    train_opt = optax.adam(train_lr)\n",
        "    weights = [edge.forward_fn for edge in network.edges]\n",
        "    train_opt_state = train_opt.init(eqx.filter(weights, eqx.is_array))\n",
        "    \n",
        "    print(\"=\" * 70)\n",
        "    print(\"Training Generative ResNet on Tiny-ImageNet\")\n",
        "    print(\"=\" * 70)\n",
        "    print(f\"Epochs: {epochs}\")\n",
        "    print(f\"Training LR: {train_lr}\")\n",
        "    print(f\"Inference LR: {inf_lr}\")\n",
        "    print(f\"Inference epochs: {inf_epoch}\")\n",
        "    if save_dir:\n",
        "        print(f\"Saving images to: {save_dir}\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        print(f\"{'='*70}\")\n",
        "        \n",
        "        batch_count = 0\n",
        "        epoch_energy = 0.0\n",
        "        \n",
        "        for batch in train_loader:\n",
        "            batch_count += 1\n",
        "            key, subkey = jr.split(key)\n",
        "            \n",
        "            input_states = {\n",
        "                \"input\": jnp.zeros((batch[\"input\"].shape[0], 1)),\n",
        "                \"output\": batch[\"input\"]\n",
        "            }\n",
        "            \n",
        "            train_opt_state, energy, _ = network.train_step(\n",
        "                input_states=input_states,\n",
        "                key=subkey,\n",
        "                train_opt=train_opt,\n",
        "                train_opt_state=train_opt_state,\n",
        "                inf_lr=inf_lr,\n",
        "                inf_epoch=inf_epoch + epoch*10 + batch_count // 10,\n",
        "            )\n",
        "            \n",
        "            epoch_energy += energy\n",
        "            \n",
        "            if batch_count % 10 == 0:\n",
        "                avg_energy = epoch_energy / batch_count\n",
        "                print(f\"  Batch {batch_count:3d} | Avg Energy: {avg_energy:.6f}\")\n",
        "            \n",
        "            if batch_count > 0 and batch_count % generate_every == 0:\n",
        "                print(f\"\\n  Generating samples at Epoch {epoch + 1}, Batch {batch_count}...\")\n",
        "                key, gen_key = jr.split(key)\n",
        "                generated = generate_images(network, gen_key, num_samples=num_generate)\n",
        "                generated_np = np.array(generated)\n",
        "                \n",
        "                save_path = None\n",
        "                if save_dir:\n",
        "                    save_path = save_dir / f\"epoch_{epoch+1:02d}_batch_{batch_count:03d}.png\"\n",
        "                \n",
        "                plot_images_grid(\n",
        "                    generated_np,\n",
        "                    rows=4,\n",
        "                    cols=4,\n",
        "                    title=f\"Generated (Epoch {epoch + 1}, Batch {batch_count})\",\n",
        "                    save_path=save_path\n",
        "                )\n",
        "        \n",
        "        print(f\"\\n  Final generation for Epoch {epoch + 1}...\")\n",
        "        key, gen_key = jr.split(key)\n",
        "        generated = generate_images(network, gen_key, num_samples=num_generate)\n",
        "        generated_np = np.array(generated)\n",
        "        \n",
        "        save_path = None\n",
        "        if save_dir:\n",
        "            save_path = save_dir / f\"epoch_{epoch+1:02d}_final.png\"\n",
        "        \n",
        "        plot_images_grid(\n",
        "            generated_np,\n",
        "            rows=4,\n",
        "            cols=4,\n",
        "            title=f\"Generated (Epoch {epoch + 1} - Final)\",\n",
        "            save_path=save_path\n",
        "        )\n",
        "        \n",
        "        avg_epoch_energy = epoch_energy / batch_count\n",
        "        print(f\"\\nEpoch {epoch + 1} Average Energy: {avg_epoch_energy:.6f}\")\n",
        "    \n",
        "    return network\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set hyperparameters and initialize the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "latent_dim = 128\n",
        "initial_channels = 512\n",
        "initial_size = 4\n",
        "img_size = 64\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "train_lr = 2e-3\n",
        "inf_lr = 0.05\n",
        "inf_epoch = 50\n",
        "num_train_samples = 10000  # Use subset for faster training\n",
        "\n",
        "# Directory to save generated images\n",
        "\n",
        "print(\"Configuration:\")\n",
        "print(f\"  Latent dim: {latent_dim}\")\n",
        "print(f\"  Initial: {initial_channels} channels at {initial_size}x{initial_size}\")\n",
        "print(f\"  Output: 3 channels at {img_size}x{img_size}\")\n",
        "print(f\"  Batch size: {batch_size}\")\n",
        "print(f\"  Epochs: {epochs}\")\n",
        "print(f\"  Training LR: {train_lr}\")\n",
        "print(f\"  Inference LR: {inf_lr}\")\n",
        "print(f\"  Inference epochs: {inf_epoch}\")\n",
        "print(f\"  Num train samples: {num_train_samples}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize random key\n",
        "key = jr.PRNGKey(42)\n",
        "key, model_key = jr.split(key)\n",
        "\n",
        "print(\"Creating Generative ResNet ChainNetwork...\")\n",
        "network = create_generative_resnet(\n",
        "    key=model_key,\n",
        "    latent_dim=latent_dim,\n",
        "    initial_channels=initial_channels,\n",
        "    initial_size=initial_size,\n",
        "    img_size=img_size,\n",
        ")\n",
        "\n",
        "print(f\"Network created with {len(network.edges)} edges\")\n",
        "print(f\"Input vertex: {network.input_vertex_name}\")\n",
        "\n",
        "print(\"\\nArchitecture:\")\n",
        "for i, edge in enumerate(network.edges):\n",
        "    from_shape = edge.from_v.shape\n",
        "    to_shape = edge.to_v.shape\n",
        "    print(f\"  Edge {i}: {edge.from_v.name} {from_shape} -> {edge.to_v.name} {to_shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Loading Tiny-ImageNet dataset...\")\n",
        "train_loader, val_loader = get_tiny_imagenet_dataloaders(\n",
        "    batch_size=batch_size,\n",
        "    img_size=img_size,\n",
        "    num_train_samples=num_train_samples,\n",
        "    shuffle_train=True\n",
        ")\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(\"Dataset loaded successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Samples Before Training\n",
        "\n",
        "Let's see what the model generates before training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"Generating samples BEFORE training...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "key, gen_key = jr.split(key)\n",
        "generated = generate_images(network, gen_key, num_samples=16)\n",
        "generated_np = np.array(generated)\n",
        "\n",
        "save_path = Path(save_dir) / \"before_training.png\"\n",
        "plot_images_grid(generated_np, rows=4, cols=4, title=\"Before Training\", save_path=save_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the Model\n",
        "\n",
        "Now let's train the model! This will take some time. Images will be generated periodically during training and saved to the `generated_images` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "key, train_key = jr.split(key)\n",
        "\n",
        "network = train_generative_model(\n",
        "    network=network,\n",
        "    train_loader=train_loader,\n",
        "    key=train_key,\n",
        "    epochs=epochs,\n",
        "    train_lr=train_lr,\n",
        "    inf_lr=inf_lr,\n",
        "    inf_epoch=inf_epoch,\n",
        "    generate_every=50,\n",
        "    num_generate=16,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Samples After Training\n",
        "\n",
        "Let's see the final results after training!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Generating samples AFTER training...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "key, gen_key = jr.split(key)\n",
        "generated = generate_images(network, gen_key, num_samples=16)\n",
        "generated_np = np.array(generated)\n",
        "\n",
        "save_path = Path(save_dir) / \"after_training_final.png\"\n",
        "plot_images_grid(generated_np, rows=4, cols=4, title=\"After Training - Final Results\", save_path=save_path)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Training Complete!\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"All generated images have been saved to: {save_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (Optional) Generate More Samples\n",
        "\n",
        "You can run this cell multiple times to generate different batches of images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate a new batch of samples\n",
        "key, gen_key = jr.split(key)\n",
        "generated = generate_images(network, gen_key, num_samples=16)\n",
        "generated_np = np.array(generated)\n",
        "\n",
        "plot_images_grid(generated_np, rows=4, cols=4, title=\"Additional Generated Samples\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
